import streamlit as st
from groq import Groq
import tempfile
import os
from pydub import AudioSegment

st.title("ğŸ™ï¸ èªéŸ³è½‰æ–‡å­— (Speech to Text)")

st.info("å¹«åŠ©å¯«ä½œæ¥­ ã® å·¥å…· By Eason")

client = Groq(api_key="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")

# Max file size in MB (Groq limit is 25MB)
MAX_FILE_SIZE_MB = 20

uploaded_file = st.file_uploader("ä¸Šå‚³éŸ³æª”", type=["m4a", "mp3", "wav", "webm", "ogg", "flac"])

if uploaded_file is not None:
    file_size_mb = len(uploaded_file.getvalue()) / (1024 * 1024)
    st.success(f"âœ… å·²ä¸Šå‚³ï¼š{uploaded_file.name} ({file_size_mb:.2f} MB)")
    
    if st.button("é–‹å§‹è½‰æ›"):
        with st.spinner("è½‰æ›ä¸­ï¼Œè«‹ç¨å€™..."):
            tmp_file_path = None
            chunk_paths = []
            try:
                # Save to temporary file
                suffix = f".{uploaded_file.name.split('.')[-1]}"
                with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                # Check if file needs to be split
                if file_size_mb > MAX_FILE_SIZE_MB:
                    st.info(f"éŸ³æª”è¼ƒå¤§ ({file_size_mb:.2f} MB)ï¼Œå°‡åˆ†æ®µè™•ç†...")
                    
                    # Load audio file
                    audio = AudioSegment.from_file(tmp_file_path)
                    total_duration = len(audio)
                    
                    # Split into 3 chunks
                    chunk_duration = total_duration // 3
                    chunks = []
                    
                    for i in range(3):
                        start = i * chunk_duration
                        end = total_duration if i == 2 else (i + 1) * chunk_duration
                        chunk = audio[start:end]
                        
                        # Save chunk to temporary file
                        chunk_path = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3").name
                        chunk.export(chunk_path, format="mp3")
                        chunk_paths.append(chunk_path)
                        chunks.append(chunk_path)
                    
                    # Transcribe each chunk
                    all_text = []
                    all_segments = []
                    
                    for idx, chunk_path in enumerate(chunks):
                        st.write(f"è™•ç†ç¬¬ {idx + 1}/3 æ®µ...")
                        with open(chunk_path, "rb") as audio_file:
                            transcription = client.audio.transcriptions.create(
                                file=audio_file,
                                model="whisper-large-v3",
                                temperature=0,
                                response_format="verbose_json",
                            )
                        
                        if hasattr(transcription, 'text'):
                            all_text.append(transcription.text)
                        
                        if hasattr(transcription, 'segments'):
                            all_segments.extend(transcription.segments)
                    
                    st.success("è½‰æ›å®Œæˆï¼")
                    
                    # Display merged text
                    st.subheader("å®Œæ•´æ–‡å­—")
                    merged_text = " ".join(all_text)
                    st.write(merged_text)
                    
                    # Display all segments
                    if all_segments:
                        st.subheader("åˆ†æ®µå…§å®¹")
                        for segment in all_segments:
                            st.write(segment['text'])
                
                else:
                    # Process normally for small files
                    with open(tmp_file_path, "rb") as audio_file:
                        transcription = client.audio.transcriptions.create(
                            file=audio_file,
                            model="whisper-large-v3",
                            temperature=0,
                            response_format="verbose_json",
                        )
                    
                    st.success("è½‰æ›å®Œæˆï¼")
                    
                    # Display full text
                    if hasattr(transcription, 'text'):
                        st.subheader("å®Œæ•´æ–‡å­—")
                        st.write(transcription.text)
                    
                    # Display segments
                    if hasattr(transcription, 'segments'):
                        st.subheader("åˆ†æ®µå…§å®¹")
                        for segment in transcription.segments:
                            st.write(segment['text'])
            
            except Exception as e:
                st.error(f"è½‰æ›å¤±æ•—ï¼š{str(e)}")
            
            finally:
                # Clean up temporary files
                if tmp_file_path and os.path.exists(tmp_file_path):
                    os.unlink(tmp_file_path)
                
                for chunk_path in chunk_paths:
                    if os.path.exists(chunk_path):
                        os.unlink(chunk_path)